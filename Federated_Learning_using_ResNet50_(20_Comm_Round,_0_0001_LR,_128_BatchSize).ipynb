{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BOEHWgTgOjD"
   },
   "source": [
    "üß© STEP 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yizb0cjhf04-",
    "outputId": "7ba233a2-9880-49da-f94d-cf7bdec3b4c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-Nqmu_fgZ6a"
   },
   "source": [
    "üóÇ STEP 2: Set up paths and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8mpzKjFgYzM",
    "outputId": "631f62dd-736f-4f0c-ad89-f6356d7665b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy scikit-learn\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j24wPZSBgfhW"
   },
   "outputs": [],
   "source": [
    "# Change path according to your dataset folder\n",
    "DATA_DIR = \"/content/drive/MyDrive/PCOS MINOR/data/train\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLIENTS = 10\n",
    "LOCAL_EPOCHS = 2\n",
    "COMMS_ROUNDS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "OUTPUT_WEIGHTS_FILE = \"/content/drive/MyDrive/PCOS MINOR/Federated_ResNet50_PCOS (20 Comm Round 128 BS).h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWZQGftxgkN9"
   },
   "source": [
    "üß† STEP 3: Define the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoR6Z31vgjXF"
   },
   "outputs": [],
   "source": [
    "def build_resnet50_model(num_classes, input_shape=(224,224,3), dropout_rate=0.3):\n",
    "    base = tf.keras.applications.ResNet50(\n",
    "        include_top=False, weights='imagenet',\n",
    "        input_shape=input_shape, pooling='avg'\n",
    "    )\n",
    "    base.trainable = False\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def gather_filepaths_and_labels(data_dir):\n",
    "    classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    paths, labels = [], []\n",
    "    for idx, cls in enumerate(classes):\n",
    "        cls_dir = os.path.join(data_dir, cls)\n",
    "        for f in os.listdir(cls_dir):\n",
    "            fpath = os.path.join(cls_dir, f)\n",
    "            if os.path.isfile(fpath):\n",
    "                paths.append(fpath)\n",
    "                labels.append(idx)\n",
    "    return np.array(paths), np.array(labels), classes\n",
    "\n",
    "def paths_to_dataset(paths, labels, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(paths))\n",
    "    def load_img(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMAGE_SIZE)\n",
    "        img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "        return img, label\n",
    "    ds = ds.map(load_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def shard_data(paths, labels, num_clients):\n",
    "    idx = np.arange(len(paths))\n",
    "    np.random.shuffle(idx)\n",
    "    paths, labels = paths[idx], labels[idx]\n",
    "    shards = []\n",
    "    n = len(paths) // num_clients\n",
    "    for i in range(num_clients):\n",
    "        start, end = i * n, (i + 1) * n if i != num_clients - 1 else len(paths)\n",
    "        shards.append((paths[start:end], labels[start:end]))\n",
    "    return shards\n",
    "\n",
    "def scale_weights(weights, scalar):\n",
    "    return [w * scalar for w in weights]\n",
    "\n",
    "def aggregate_scaled_weights(scaled_weights_list):\n",
    "    avg = []\n",
    "    for layer in zip(*scaled_weights_list):\n",
    "        avg.append(np.sum(layer, axis=0))\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-bWftL5grHA"
   },
   "source": [
    "üîÑ STEP 4: Federated Training (FedAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vsc_72_NgtQQ",
    "outputId": "b501645b-0259-478e-f47b-a7240bc83463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 classes: ['infected', 'notinfected']\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\n",
      "--- Communication Round 1/20 ---\n",
      "Round 1 - Global Test Loss: 0.9086 | Accuracy: 50.9091%\n",
      "\n",
      "--- Communication Round 2/20 ---\n",
      "Round 2 - Global Test Loss: 0.7954 | Accuracy: 56.1039%\n",
      "\n",
      "--- Communication Round 3/20 ---\n",
      "Round 3 - Global Test Loss: 0.7113 | Accuracy: 60.5195%\n",
      "\n",
      "--- Communication Round 4/20 ---\n",
      "Round 4 - Global Test Loss: 0.6391 | Accuracy: 63.8961%\n",
      "\n",
      "--- Communication Round 5/20 ---\n",
      "Round 5 - Global Test Loss: 0.5736 | Accuracy: 66.2338%\n",
      "\n",
      "--- Communication Round 6/20 ---\n",
      "Round 6 - Global Test Loss: 0.5123 | Accuracy: 69.3506%\n",
      "\n",
      "--- Communication Round 7/20 ---\n",
      "Round 7 - Global Test Loss: 0.4544 | Accuracy: 72.7273%\n",
      "\n",
      "--- Communication Round 8/20 ---\n",
      "Round 8 - Global Test Loss: 0.4041 | Accuracy: 76.3636%\n",
      "\n",
      "--- Communication Round 9/20 ---\n",
      "Round 9 - Global Test Loss: 0.3607 | Accuracy: 80.7792%\n",
      "\n",
      "--- Communication Round 10/20 ---\n",
      "Round 10 - Global Test Loss: 0.3213 | Accuracy: 85.7143%\n",
      "\n",
      "--- Communication Round 11/20 ---\n",
      "Round 11 - Global Test Loss: 0.2860 | Accuracy: 90.1299%\n",
      "\n",
      "--- Communication Round 12/20 ---\n",
      "Round 12 - Global Test Loss: 0.2537 | Accuracy: 94.0260%\n",
      "\n",
      "--- Communication Round 13/20 ---\n",
      "Round 13 - Global Test Loss: 0.2258 | Accuracy: 95.8442%\n",
      "\n",
      "--- Communication Round 14/20 ---\n",
      "Round 14 - Global Test Loss: 0.2005 | Accuracy: 96.8831%\n",
      "\n",
      "--- Communication Round 15/20 ---\n",
      "Round 15 - Global Test Loss: 0.1804 | Accuracy: 96.8831%\n",
      "\n",
      "--- Communication Round 16/20 ---\n",
      "Round 16 - Global Test Loss: 0.1607 | Accuracy: 97.6623%\n",
      "\n",
      "--- Communication Round 17/20 ---\n",
      "Round 17 - Global Test Loss: 0.1463 | Accuracy: 97.9221%\n",
      "\n",
      "--- Communication Round 18/20 ---\n",
      "Round 18 - Global Test Loss: 0.1329 | Accuracy: 98.1818%\n",
      "\n",
      "--- Communication Round 19/20 ---\n",
      "Round 19 - Global Test Loss: 0.1186 | Accuracy: 98.7013%\n",
      "\n",
      "--- Communication Round 20/20 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 20 - Global Test Loss: 0.1071 | Accuracy: 99.2208%\n",
      "\n",
      "‚úÖ Training complete! Model saved to /content/drive/MyDrive/PCOS MINOR/Federated_ResNet50_PCOS (20 Comm Round 128 BS).h5\n"
     ]
    }
   ],
   "source": [
    "def run_fedavg():\n",
    "    # Load dataset\n",
    "    paths, labels, classes = gather_filepaths_and_labels(DATA_DIR)\n",
    "    print(f\"Found {len(classes)} classes: {classes}\")\n",
    "\n",
    "    # Split into train/test\n",
    "    p_train, p_test, y_train, y_test = train_test_split(paths, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "    shards = shard_data(p_train, y_train, NUM_CLIENTS)\n",
    "    clients = {f\"client_{i+1}\": {\"paths\": shards[i][0], \"labels\": shards[i][1]} for i in range(NUM_CLIENTS)}\n",
    "\n",
    "    # Build global model\n",
    "    global_model = build_resnet50_model(num_classes=len(classes))\n",
    "    global_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    test_ds = paths_to_dataset(p_test, y_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    total_samples = len(p_train)\n",
    "\n",
    "    for rnd in range(1, COMMS_ROUNDS + 1):\n",
    "        print(f\"\\n--- Communication Round {rnd}/{COMMS_ROUNDS} ---\")\n",
    "        scaled_local_weights = []\n",
    "\n",
    "        for cname, data in clients.items():\n",
    "            local_ds = paths_to_dataset(data[\"paths\"], data[\"labels\"], batch_size=BATCH_SIZE)\n",
    "            local_model = tf.keras.models.clone_model(global_model)\n",
    "            local_model.build((None, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            local_model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            local_model.fit(local_ds, epochs=LOCAL_EPOCHS, verbose=0)\n",
    "\n",
    "            scaling_factor = len(data[\"labels\"]) / total_samples\n",
    "            scaled_local_weights.append(scale_weights(local_model.get_weights(), scaling_factor))\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "        # Aggregate updates\n",
    "        new_weights = aggregate_scaled_weights(scaled_local_weights)\n",
    "        global_model.set_weights(new_weights)\n",
    "\n",
    "        # Evaluate global model\n",
    "        loss, acc = global_model.evaluate(test_ds, verbose=0)\n",
    "        print(f\"Round {rnd} - Global Test Loss: {loss:.4f} | Accuracy: {acc:.4%}\")\n",
    "\n",
    "    global_model.save(OUTPUT_WEIGHTS_FILE)\n",
    "    print(f\"\\n‚úÖ Training complete! Model saved to {OUTPUT_WEIGHTS_FILE}\")\n",
    "\n",
    "run_fedavg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHD7f_9IhZaH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
